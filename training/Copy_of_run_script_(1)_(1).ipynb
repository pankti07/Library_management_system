{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy_of_run_script (1) (1).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.7"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "eCWLTzTRoxMk",
        "colab_type": "code",
        "outputId": "84e05056-3eeb-4eba-b936-c9de49142985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "from RecommendationModel import RecommendationModel\n",
        "from DataPreprocessing import DataPreprocessing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "13L9K66fubJL",
        "colab_type": "code",
        "outputId": "353db365-294b-48e8-f6fc-d78d4104b5e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        }
      },
      "cell_type": "code",
      "source": [
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip install gputil\n",
        "!pip install psutil\n",
        "!pip install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gputil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: gputil\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built gputil\n",
            "Installing collected packages: gputil\n",
            "Successfully installed gputil-1.4.0\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (5.4.8)\n",
            "Requirement already satisfied: humanize in /usr/local/lib/python3.6/dist-packages (0.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DnZnKkBXpoCF",
        "colab_type": "code",
        "outputId": "549fdaa1-f045-49ed-8e3b-579c305f549b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ZPXnTqrTsz1m",
        "colab_type": "code",
        "outputId": "f861e4cb-36d9-411d-f84d-bbac5efaeedc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "cell_type": "code",
      "source": [
        "!unzip \"/content/gdrive/My Drive/CollaborativeFiltering/movielens-20m-dataset.zip\""
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/gdrive/My Drive/CollaborativeFiltering/movielens-20m-dataset.zip\n",
            "  inflating: movie.csv               \n",
            "  inflating: link.csv                \n",
            "  inflating: tag.csv                 \n",
            "  inflating: genome_tags.csv         \n",
            "  inflating: rating.csv              \n",
            "  inflating: genome_scores.csv       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4nzHr8UjoxM_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataPreprocessing = DataPreprocessing()\n",
        "\n",
        "#getting training data\n",
        "userIds, movieIds, ratings, rating_csv, movie_csv = dataPreprocessing.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y5HmAfRRoxNK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "outputId": "498dda7c-7178-4724-96da-88880926cca1"
      },
      "cell_type": "code",
      "source": [
        "#getting emmbeding model with Dense layers\n",
        "rModel = RecommendationModel(dataPreprocessing.max_userId, dataPreprocessing.max_movieId, dataPreprocessing.k_factor)\n",
        "model = rModel.generate_embeddedModel()\n",
        "model.compile(loss='mse',\n",
        "              optimizer='adamax')\n",
        "print(model.summary())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "embedding_1_input (InputLayer)  (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2_input (InputLayer)  (None, 1)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 1, 128)       17727104    embedding_1_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, 1, 128)       16801536    embedding_2_input[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 128)          0           embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "reshape_2 (Reshape)             (None, 128)          0           embedding_2[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dot_1 (Dot)                     (None, 1)            0           reshape_1[0][0]                  \n",
            "                                                                 reshape_2[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 34,528,640\n",
            "Trainable params: 34,528,640\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rKChc1ykuqVq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "bae60e04-fdb6-4adc-9cf6-cd5ca28bd608"
      },
      "cell_type": "code",
      "source": [
        "GPUs = GPU.getGPUs()\n",
        "# XXX: only one GPU on Colab and isn’t guaranteed\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 11.0 GB  | Proc size: 4.1 GB\n",
            "GPU RAM Free: 15079MB | Used: 0MB | Util   0% | Total 15079MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nbtH5K6eoxNT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "outputId": "4df8b157-379d-42bc-9957-cb6c6bb995d7"
      },
      "cell_type": "code",
      "source": [
        "############## Training part ################\n",
        "print('userIds : ',userIds, ' shape : ',userIds.shape)\n",
        "print('movieIds : ',movieIds, ' shape : ',movieIds.shape)\n",
        "print('ratings : ',ratings, ' shape : ',ratings.shape)\n",
        "print('start training...........')\n",
        "filepath = 'weights_best_embedded.hdf5'\n",
        "checkPoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True)\n",
        "callbacks_lst = [checkPoint]\n",
        "model.fit([userIds, movieIds], ratings, validation_split=0.1, epochs=10, batch_size=512, callbacks=callbacks_lst)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "userIds :  [ 41196 121765 122597 ... 117582 105673 114726]  shape :  (20000263,)\n",
            "movieIds :  [ 1952 58559  1219 ...  6375   597   527]  shape :  (20000263,)\n",
            "ratings :  [5. 4. 5. ... 5. 3. 3.]  shape :  (20000263,)\n",
            "start training...........\n",
            "Train on 18000236 samples, validate on 2000027 samples\n",
            "Epoch 1/10\n",
            "18000236/18000236 [==============================] - 742s 41us/step - loss: 3.8209 - val_loss: 1.0774\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.07744, saving model to weights_best_embedded.hdf5\n",
            "Epoch 2/10\n",
            "18000236/18000236 [==============================] - 739s 41us/step - loss: 0.9130 - val_loss: 0.8350\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.07744 to 0.83504, saving model to weights_best_embedded.hdf5\n",
            "Epoch 3/10\n",
            "18000236/18000236 [==============================] - 738s 41us/step - loss: 0.7827 - val_loss: 0.7623\n",
            "\n",
            "Epoch 00003: val_loss improved from 0.83504 to 0.76230, saving model to weights_best_embedded.hdf5\n",
            "Epoch 4/10\n",
            "18000236/18000236 [==============================] - 738s 41us/step - loss: 0.7190 - val_loss: 0.7186\n",
            "\n",
            "Epoch 00004: val_loss improved from 0.76230 to 0.71860, saving model to weights_best_embedded.hdf5\n",
            "Epoch 5/10\n",
            "18000236/18000236 [==============================] - 737s 41us/step - loss: 0.6685 - val_loss: 0.6879\n",
            "\n",
            "Epoch 00005: val_loss improved from 0.71860 to 0.68786, saving model to weights_best_embedded.hdf5\n",
            "Epoch 6/10\n",
            "18000236/18000236 [==============================] - 738s 41us/step - loss: 0.6233 - val_loss: 0.6657\n",
            "\n",
            "Epoch 00006: val_loss improved from 0.68786 to 0.66575, saving model to weights_best_embedded.hdf5\n",
            "Epoch 7/10\n",
            "18000236/18000236 [==============================] - 737s 41us/step - loss: 0.5814 - val_loss: 0.6517\n",
            "\n",
            "Epoch 00007: val_loss improved from 0.66575 to 0.65172, saving model to weights_best_embedded.hdf5\n",
            "Epoch 8/10\n",
            "18000236/18000236 [==============================] - 737s 41us/step - loss: 0.5419 - val_loss: 0.6445\n",
            "\n",
            "Epoch 00008: val_loss improved from 0.65172 to 0.64450, saving model to weights_best_embedded.hdf5\n",
            "Epoch 9/10\n",
            "18000236/18000236 [==============================] - 739s 41us/step - loss: 0.5049 - val_loss: 0.6426\n",
            "\n",
            "Epoch 00009: val_loss improved from 0.64450 to 0.64264, saving model to weights_best_embedded.hdf5\n",
            "Epoch 10/10\n",
            "18000236/18000236 [==============================] - 739s 41us/step - loss: 0.4715 - val_loss: 0.6454\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 0.64264\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f48201da908>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "TWbAdX18prmb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "uXTxoAD_psn2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_save_name = ''\n",
        "path = F\"/content/gdrive/My Drive/CollaborativeFiltering/{filepath}\" \n",
        "model.save_weights(path)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}